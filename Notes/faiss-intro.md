# Basics of FAISS

FAISS (Facebook AI Similarity Search) is a library designed for efficient similarity search and clustering of dense vectors. It addresses the challenge of quickly finding vectors similar to a query vector within a large database, which is crucial for applications like image search, recommendation systems, and natural language processing.

## Key Features and Methods

*   **Vector Representation**: FAISS assumes that data instances are represented as high-dimensional vectors generated by machine learning algorithms.
*   **Similarity Measures**: It supports various similarity or distance measures, including L2 (Euclidean) distance, dot product, and cosine similarity. Similar vectors are those with the lowest L2 distance or the highest dot product or cosine similarity with the query vector.
*   **Index Structures**: FAISS builds index structures to facilitate fast search. These indexes come in different types, each tailored to specific use cases and data characteristics. Examples include IVF (Inverted File with Vocabulary Tree) for high-dimensional data and HNSW (Hierarchical Navigable Small World) for low-dimensional spaces.
*   **Vector Quantization**: FAISS often utilizes techniques like vector quantization to reduce the dimensionality of the vectors while preserving their essential characteristics. This speeds up the search process by working with compressed representations of the original data.
*   **GPU Acceleration**: FAISS provides GPU implementations that can significantly accelerate similarity searches, especially on servers equipped with GPUs. It supports both single and multi-GPU usage, allowing for parallel processing.

## How FAISS Works

FAISS works by building index structures that organize vectors to facilitate fast searching. The process involves:

1.  **Initialization**: Start by initializing an empty index structure using FAISS's built-in functions. You can choose from various index types provided by FAISS, such as flat, IVF (Inverted File with Inverted List), or HNSW (Hierarchical Navigable Small World), depending on your dataset characteristics and the type of search queries you anticipate.
2.  **Data Addition**: Add your preprocessed data vectors once the index structure is set up. This step populates the index with your dataset, helping FAISS perform similarity searches efficiently.
3.  **Index Parameter Optimization**: Optimizing index parameters is crucial for achieving improved search performance. You can experiment with different parameter configurations based on your dataset characteristics, such as the number of data points, the dimensionality of vectors, and the nature of similarity queries. FAISS provides methods for tuning these parameters to maximize search efficiency.

## FAISS vs. Other Databases

Unlike traditional databases, FAISS is specifically designed for similarity search on vector data. While traditional databases focus on structured data and exact matches, FAISS excels at finding approximate nearest neighbors in high-dimensional spaces.

| Feature                 | FAISS                                                                                                | Traditional Databases                                                                         |
| :---------------------- | :--------------------------------------------------------------------------------------------------- | :---------------------------------------------------------------------------------------------- |
| **Data Type**           | Dense vectors                                                                                        | Structured data (e.g., tables with rows and columns)                                          |
| **Search Type**         | Similarity search (approximate nearest neighbors)                                                    | Exact match, range queries                                                                    |
| **Indexing**            | Specialized index structures (e.g., IVF, HNSW)                                                       | B-trees, hash indexes                                                                         |
| **Use Cases**           | Image search, recommendation systems, NLP                                                              | Transaction processing, data warehousing                                                       |
| **Scalability**         | Designed for large-scale vector data                                                                 | Scalable, but may struggle with high-dimensional similarity search                               |
| **Memory Management**   | Index compression, efficient data loading, memory mapping                                           | Depends on the specific database system                                                         |
| **Search Algorithms**   | k-means clustering, proximity graph-based methods, Lloydâ€™s k-means, Small k-Selection              | Traditional indexing and search algorithms                                                     |

## Data Storage in FAISS

FAISS stores data as dense vectors and uses various techniques to optimize memory usage and search speed. Some key strategies include:

*   **Index Compression**: Using compressed indexes like `IndexPQ` (Product Quantization) can significantly reduce memory usage. This method compresses vectors, making it possible to store and search through larger datasets without exhausting memory resources.
*   **Efficient Data Loading**: Loading data in batches rather than all at once to avoid memory overflow is crucial. This approach is beneficial when dealing with massive datasets that cannot fit into RAM entirely.
*   **Memory Mapping**: Utilizing memory-mapped files to handle large indexes. FAISS supports memory mapping, allowing you to load parts of the index into memory as needed, thus conserving RAM.

FAISS focuses on methods that compress the original vectors because they're the only ones that scale to datasets of billions of vectors. By adopting memory management strategies, you can maximize the efficiency of your FAISS vector database, ensuring it remains responsive and capable of handling large volumes of data.

### A little more on PQ:
Product quantization (PQ) is a technique used to compress high-dimensional vectors into a more memory-efficient representation. It's useful for reducing the memory footprint of indexes.

#### How Product Quantization Works

The process involves converting floating-point numbers into integers. Here's a breakdown:

1.  **Vector Splitting**: A high-dimensional vector is divided into *m* smaller subvectors (also referred to as chunks) of equal size. The number of chunks is configurable, and as a rule of thumb, the lower it is, the higher the compression rate (which is good!)
2.  **Clustering (Subvector Quantization)**: Each subvector is then quantized to be represented by one of *k* centroids. This is done using the k-means algorithm. The clustering is done separately for each group of chunks. Each chunk of a vector will now be mapped to the closest centroid.
3.  **Centroid Replacement**: Instead of storing the original subvector (chunk), you store the ID of its closest centroid. If this is repeated for each chunk, the original embedding can be approximated as a vector of subsequent IDs of the centroids. This vector of IDs is also called the PQ code.

At the end of this process, the highly dimensional vector, which requires a lot of memory, is converted to a smaller vector of IDs that requires very little memory.

#### Why Use Product Quantization?

*   **Memory Reduction**: PQ significantly reduces the memory footprint of indexes, enabling the use of larger datasets
*   **Speed**: Compressing vectors to a smaller size can also speed up calculations, since less data needs to be processed.

Referemces:
https://weaviate.io/developers/academy/py/compression/pq
https://www.pinecone.io/learn/series/faiss/product-quantization/
https://qdrant.tech/articles/product-quantization/
https://www.microsoft.com/en-us/research/wp-content/uploads/2013/11/pami13opq.pdf
https://towardsdatascience.com/similarity-search-product-quantization-b2a1a6397701/
https://weaviate.io/developers/weaviate/configuration/compression/pq-compression
https://ai.gopubby.com/product-quantization-a2779ace565
